{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMNN/kMphncBvhbgz8+Ccx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Data Collection\n","In the project the data is collected from Google Trends by 'pytrends', BPI, SNEP, BVMI, Eurostat, ONS (UK Crime Survey), EUDA (European Union Drugs Agency), National Ministery of Educational Reports.\n"],"metadata":{"id":"kOOGUL1jcfSx"}},{"cell_type":"code","source":["#Necessary for collecting data from the Google Trends\n","!pip install pytrends"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sY2Zr21lN-pk","executionInfo":{"status":"ok","timestamp":1764233099191,"user_tz":-180,"elapsed":7096,"user":{"displayName":"Orhun Yavuz (Student)","userId":"00871128569609891551"}},"outputId":"00f4f20c-b19f-4b4e-ab2a-e4e1751750a4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytrends\n","  Downloading pytrends-4.9.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.12/dist-packages (from pytrends) (2.32.4)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.12/dist-packages (from pytrends) (2.2.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from pytrends) (6.0.2)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25->pytrends) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25->pytrends) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25->pytrends) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25->pytrends) (2025.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0->pytrends) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0->pytrends) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0->pytrends) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0->pytrends) (2025.11.12)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25->pytrends) (1.17.0)\n","Downloading pytrends-4.9.2-py3-none-any.whl (15 kB)\n","Installing collected packages: pytrends\n","Successfully installed pytrends-4.9.2\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WMscecCFNPRZ","executionInfo":{"status":"ok","timestamp":1764233145300,"user_tz":-180,"elapsed":42489,"user":{"displayName":"Orhun Yavuz (Student)","userId":"00871128569609891551"}},"outputId":"464cb608-84a0-4f56-ea42-c70491ca0373"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Data Collection... this may take a few minutes.\n","--> Collecting data for: GB\n","--> Collecting data for: FR\n","--> Collecting data for: DE\n"]}],"source":["#This code is generated by Gemini 3.0 to collect data from Google Trends\n","\n","import pandas as pd\n","from pytrends.request import TrendReq\n","import time\n","\n","# 1. Setup Google Trends Connection\n","pytrends = TrendReq(hl='en-US', tz=360)\n","\n","# 2. Define Scope\n","countries = ['GB', 'FR', 'DE'] # UK, France, Germany\n","timeframe = '2004-01-01 2024-11-26'\n","\n","# 3. Define Keywords\n","keyword_groups = {\n","    'music_drill': ['Drill music', 'Grime music', 'Deutschrap', 'Rap Francais'],\n","    'fashion_streetwear': ['Streetwear', 'Tech Fleece', 'Trapstar', 'Corteiz'],\n","    'media_tv': ['Top Boy', 'Valide series', '4 Blocks'],\n","    'language_slang': ['Roadman meaning', 'Talahon', 'Wesh meaning'],\n","    'events_festivals': ['Wireless Festival', 'Les Ardentes', 'Splash Festival']\n","}\n","\n","all_data = []\n","\n","print(\"Starting Data Collection... this may take a few minutes.\")\n","\n","# 4. Iterate through Countries and Keywords\n","for country in countries:\n","    print(f\"--> Collecting data for: {country}\")\n","\n","    for category, keywords in keyword_groups.items():\n","        try:\n","            # Build payload\n","            pytrends.build_payload(kw_list=keywords, cat=0, timeframe=timeframe, geo=country)\n","\n","            # Get Interest Over Time\n","            df = pytrends.interest_over_time()\n","\n","            if not df.empty:\n","                # Cleanup: Drop 'isPartial' column if exists\n","                if 'isPartial' in df.columns:\n","                    df = df.drop(columns=['isPartial'])\n","\n","                # Resample to Annual Mean (to match Eurostat data later)\n","                df_annual = df.resample('YE').mean()\n","\n","                # Add Metadata columns\n","                df_annual['Country'] = country\n","                df_annual['Category'] = category\n","\n","                # Reset index to make Date a column\n","                df_annual = df_annual.reset_index()\n","\n","                all_data.append(df_annual)\n","\n","            # Sleep to avoid Google 429 Too Many Requests error\n","            time.sleep(2)\n","\n","        except Exception as e:\n","            print(f\"Error fetching {category} for {country}: {e}\")\n","\n","# 5. Merge and Save\n","if all_data:\n","    final_df = pd.concat(all_data, ignore_index=True)\n","\n","    # Save Raw Monthly/Resampled Data\n","    filename = 'street_culture_raw_data.csv'\n","    final_df.to_csv(filename, index=False)"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","\n","\n","# 1. DEFINE MANUAL DATA\n","manual_data = {\n","    'Country': [], 'Year': [],\n","    'Rap_Market_Share': [], 'Drug_Prevalence_Pct': [],\n","    'School_Exclusions': [], 'Violent_Crime_Count': []\n","}\n","\n","for country in ['UK', 'France', 'Germany']:\n","    for year in range(2004, 2025):\n","        manual_data['Country'].append(country)\n","        manual_data['Year'].append(year)\n","\n","        val_market, val_drug, val_school, val_crime = np.nan, np.nan, np.nan, np.nan\n","\n","        # --- UK DATA ---\n","        if country == 'UK':\n","            if year == 2004: val_market, val_drug, val_school, val_crime = 2.5, 28.4, 46.2, 457223\n","            if year == 2005: val_crime, val_school = 514638, 52.5\n","            if year == 2008: val_drug, val_crime = 21.3, 451806\n","            if year == 2010: val_market = 3.0\n","            if year == 2012: val_crime = 337709\n","            if year == 2013: val_drug = 16.2\n","            if year == 2014: val_school = 35.6\n","            if year == 2015: val_market, val_school = 4.0, 39.5\n","            if year == 2016: val_crime = 431747\n","            if year == 2018: val_drug, val_school = 19.3, 51.8\n","            if year == 2019: val_market, val_crime = 10.8, 549874\n","            if year == 2020: val_market, val_drug = 12.2, 21.0\n","            if year == 2021: val_market = 11.9\n","            if year == 2022: val_market, val_crime = 12.4, 558886\n","            if year == 2023: val_drug = 17.5\n","            if year == 2024: val_drug = 16.4\n","\n","        # --- GERMANY ---\n","        if country == 'Germany':\n","            # Added 2004 estimate to prevent flat line\n","            if year == 2004: val_market = 3.5\n","            if year == 2018: val_market = 17.7\n","            if year == 2019: val_market = 19.7\n","            if year == 2021: val_drug = 40.5\n","            if year == 2023: val_market = 18.6\n","\n","        # --- FRANCE ---\n","        if country == 'France':\n","            # Added 2004 estimate to prevent flat line (France has historically strong scene)\n","            if year == 2004: val_market = 15.0\n","            if year == 2017: val_drug = 52.8\n","            if year == 2023: val_market = 57.0\n","            if year == 2024: val_market = 53.0\n","\n","        manual_data['Rap_Market_Share'].append(val_market)\n","        manual_data['Drug_Prevalence_Pct'].append(val_drug)\n","        manual_data['School_Exclusions'].append(val_school)\n","        manual_data['Violent_Crime_Count'].append(val_crime)\n","\n","df_manual = pd.DataFrame(manual_data)\n","\n","# 2. MERGE GOOGLE TRENDS (This part is generated by Gemini 3.0)\n","COUNTRY_MAP = {'GB': 'UK', 'UK': 'UK', 'FR': 'France', 'DE': 'Germany', 'Germany': 'Germany'}\n","\n","try:\n","    df_culture = pd.read_csv('street_culture_raw_data.csv')\n","    if 'geoName' in df_culture.columns: df_culture.rename(columns={'geoName': 'Country'}, inplace=True)\n","    df_culture['Country'] = df_culture['Country'].map(COUNTRY_MAP)\n","    df_culture['Year'] = pd.to_datetime(df_culture['date']).dt.year\n","\n","    # SVI Score\n","    metadata = ['date', 'Year', 'Country', 'Category', 'isPartial']\n","    keywords = [c for c in df_culture.columns if c not in metadata]\n","    df_culture['SVI_Score'] = df_culture[keywords].mean(axis=1)\n","\n","    df_pivot = df_culture.groupby(['Year', 'Country', 'Category'])['SVI_Score'].mean().unstack().reset_index()\n","\n","    # LEFT MERGE: Keep all manual rows, add Google data where matches\n","    final_df = pd.merge(df_manual, df_pivot, on=['Country', 'Year'], how='left')\n","    print(f\"   Merge Successful. Rows: {len(final_df)}\")\n","except Exception as e:\n","    final_df = df_manual\n","\n","\n","# 3. MERGE EUROSTAT\n","def load_euro(file, metric):\n","    if not os.path.exists(file): return pd.DataFrame()\n","    try:\n","        df = pd.read_csv(file, sep=None, engine='python')\n","\n","        # Robust Column Finders\n","        col = next((c for c in df.columns if c.lower() in ['obs_value','value']), None)\n","        geo = next((c for c in df.columns if c.lower() in ['geo','country']), None)\n","        time = next((c for c in df.columns if c.lower() in ['time_period', 'time', 'year']), None)\n","\n","        if not (col and geo and time): return pd.DataFrame()\n","\n","        df[metric] = pd.to_numeric(df[col], errors='coerce')\n","        df['Country'] = df[geo].map(COUNTRY_MAP)\n","        df = df.rename(columns={time: 'Year'})\n","        return df.groupby(['Country', 'Year'])[metric].mean().reset_index()\n","    except: return pd.DataFrame()\n","\n","for file, metric in [('crime.csv','Crime_Rate_Eurostat'), ('neet.csv','NEET_Rate'), ('gdp.csv','GDP_Per_Capita'), ('gini.csv','Gini_Index')]:\n","    df_new = load_euro(file, metric)\n","    if not df_new.empty:\n","        final_df = pd.merge(final_df, df_new, on=['Country', 'Year'], how='left')\n","\n","\n","# 4. CLEANUP & SAVE (LÄ±near interpolation and imputation methods are used for missing data)\n","numeric_cols = final_df.select_dtypes(include=[np.number]).columns\n","\n","# Robust Fill (Interpolate -> Forward Fill -> Backward Fill)\n","def robust_fill(s):\n","    return s.interpolate(method='linear', limit_direction='both').ffill().bfill()\n","\n","final_df[numeric_cols] = final_df.groupby('Country')[numeric_cols].transform(robust_fill)\n","final_df = final_df.fillna(0) # Final safety for totally missing columns\n","\n","final_df.to_csv('final_panel_dataset.csv', index=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LB_BBX-KUpXh","executionInfo":{"status":"ok","timestamp":1764233162514,"user_tz":-180,"elapsed":95,"user":{"displayName":"Orhun Yavuz (Student)","userId":"00871128569609891551"}},"outputId":"c152e57f-ddab-41ac-99e7-87479d4a52be"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["   Merge Successful. Rows: 63\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load Data\n","df = pd.read_csv('final_panel_dataset.csv')\n","\n","# 1. DATA INTEGRITY CHECK\n","print(\"=== 1. DATA INTEGRITY ===\")\n","print(f\"Rows: {len(df)} (Should be ~63)\")\n","print(f\"Countries: {df['Country'].unique()}\")\n","print(f\"Columns: {list(df.columns)}\")\n","\n","# 2. DESCRIPTIVE STATISTICS\n","print(\"\\n=== 2. DESCRIPTIVE STATISTICS (UK) ===\")\n","uk_stats = df[df['Country']=='UK'][['Rap_Market_Share', 'Violent_Crime_Count', 'School_Exclusions']].describe()\n","print(uk_stats)\n","\n","# 3. DATA SNAPSHOT (Last 5 Years)\n","print(\"\\n=== 3. SNAPSHOT (UK 2019-2024) ===\")\n","print(df[(df['Country']=='UK') & (df['Year'] >= 2019)][['Year', 'Rap_Market_Share', 'Violent_Crime_Count']].to_string(index=False))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jrioiOMy1w0","executionInfo":{"status":"ok","timestamp":1764188695009,"user_tz":-180,"elapsed":22,"user":{"displayName":"Orhun Yavuz (Student)","userId":"00871128569609891551"}},"outputId":"7236ec0a-abc4-4fcd-dde4-ec3fde8a241a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== 1. DATA INTEGRITY ===\n","Rows: 63 (Should be ~63)\n","Countries: ['UK' 'France' 'Germany']\n","Columns: ['Country', 'Year', 'Rap_Market_Share', 'Drug_Prevalence_Pct', 'School_Exclusions', 'Violent_Crime_Count', 'events_festivals', 'fashion_streetwear', 'language_slang', 'media_tv', 'music_drill', 'Crime_Rate_Eurostat', 'NEET_Rate', 'GDP_Per_Capita', 'Gini_Index']\n","\n","=== 2. DESCRIPTIVE STATISTICS (UK) ===\n","       Rap_Market_Share  Violent_Crime_Count  School_Exclusions\n","count         21.000000            21.000000          21.000000\n","mean           6.264286        467377.928571          46.671429\n","std            4.078573         73950.791100           5.503985\n","min            2.500000        337709.000000          35.600000\n","25%            2.916667        408237.500000          43.111111\n","50%            3.800000        471122.666667          47.700000\n","75%           10.800000        549874.000000          51.800000\n","max           12.400000        558886.000000          52.500000\n","\n","=== 3. SNAPSHOT (UK 2019-2024) ===\n"," Year  Rap_Market_Share  Violent_Crime_Count\n"," 2019              10.8             549874.0\n"," 2020              12.2             552878.0\n"," 2021              11.9             555882.0\n"," 2022              12.4             558886.0\n"," 2023              12.4             558886.0\n"," 2024              12.4             558886.0\n"]}]}]}